{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Bandit configuration\n",
      "-------------------------\n",
      "bandit_actions: 10\n",
      "true_q_value_mean: 0.5\n",
      "true_q_value_std: 0.0\n",
      "q_value_std: 0.1\n",
      "q_drift_mean: 0.0\n",
      "q_drift_std: 0.0\n",
      "random_seed: None\n",
      "-------------------------\n",
      "Initial bandit arms q-values:[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 343.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final bandit arms q-values:[0.36936227 0.56821102 0.58782945 0.61990178 0.43582268 0.47077711\n",
      " 0.6237416  0.49539517 0.3764956  0.58312161]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO make the same thing with classes karmedexperiment and karmedcompetition\n",
    "# TODO implement proper graphs like in the former version \n",
    "# rl-specialization-coursera.exercises\n",
    "# TODO think of implementing multicore version\n",
    "# runtimes for 1e6 iterations measured 20250206, 9 am\n",
    "# @ThinkPad: 25.4s\n",
    "# @ThinkPad old approach with 2 cores: 27.5s\n",
    "# @ThinkPad old approach with 6 cores: 11.4s (only p-cores?)\n",
    "# @ThinkPad old approach with 16 cores: 8.9s (p- and e-cores)\n",
    "\n",
    "# training a basic agent\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import karmedbandit\n",
    "from karmedagents import BanditAgent\n",
    "\n",
    "episodes = 1_00\n",
    "timesteps = 1_00\n",
    "\n",
    "env = gym.make(\"BanditEnv-v0\")\n",
    "# env.random_seed = 42\n",
    "\n",
    "obs, info = env.reset()\n",
    "print(f'Initial bandit arms q-values:{env.get_wrapper_attr(\"arms_q_values\")}')\n",
    "\n",
    "agent = BanditAgent(env=env, policy=\"random\")\n",
    "\n",
    "# TODO implement Metrics\n",
    "# plt.title(f'Average loss per timestep over {runs} runs\\n{title}')\n",
    "# plt.title(f'Average rewards per timestep over {runs} runs\\n{title}')\n",
    "# plt.title(f'Cumulative Average rewards per timestep over {runs} runs\\n{title}')\n",
    "# plt.title(f'Percentage optimal actions per timestep over {runs} runs\\n{title}')\n",
    "\n",
    "for episode in tqdm(range(episodes)):\n",
    "    obs, info = env.reset()\n",
    "\n",
    "    for step in range(timesteps):  # Perform some steps\n",
    "        action = agent.get_action() #Example\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        agent.update(reward)\n",
    "        step_error, optimal_action = info.get('step_error'), info.get('optimal_action')\n",
    "        # print (step_error, optimal_action)\n",
    "\n",
    "print(f'Final bandit arms q-values:{env.get_wrapper_attr(\"arms_q_values\")}')\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing whether the env instantiation and use works in .ipynb\n",
    "\n",
    "from karmedbandit import BanditEnv\n",
    "env = BanditEnv()\n",
    "\n",
    "# XXX info: gymnasium env self test. Run as required.\n",
    "# The output in the terminal will indicate whether tests passed or failed.\n",
    "# check_env(env = env)\n",
    "\n",
    "print(env.true_q_value_mean)\n",
    "obs, info = env.reset()\n",
    "print(\"Initial arms_q_values:\", env.arms_true_q_values)\n",
    "print (\"#\"*79)\n",
    "for _ in range(10_000):  # Perform some steps\n",
    "    action = env.action_space.sample() #Example\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "print(\"Updated arms_q_values:\", np.round(env.arms_q_values, 3))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the arms_true_q_values creation works properly\n",
    "import numpy as np\n",
    "bandit_actions = 10\n",
    "\n",
    "bandit_actions: int = 10\n",
    "true_q_value_mean = 0.5, # \n",
    "true_q_value_std = 0., # for a uniform initial q-value set this to zero\n",
    "\n",
    "arms_true_q_values = np.random.normal(true_q_value_mean, true_q_value_std, bandit_actions)\n",
    "\n",
    "print(arms_true_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the ingest of BanditParams into BanditEnv\n",
    "\n",
    "import inspect\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "class BanditParams:\n",
    "    arms: int = 10\n",
    "    qdrift_mean: float = 0.0\n",
    "    qdrift_std: float = 0.0\n",
    "    stationary: bool = True\n",
    "\n",
    "class BanditEnv(gym.Env, BanditParams):\n",
    "\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 4}\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "\n",
    "env = BanditEnv()\n",
    "# print(env.arms)\n",
    "# env.arms = 6\n",
    "# print(env.arms)\n",
    "\n",
    "print(*[f\"{key}: {value}\" for key, value in env.__dict__.items()], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a violin chart to represent a distribution\n",
    "\n",
    "'''Figure 2.1: An example bandit problem from the 10-armed testbed. The true value q⇤(a) of\n",
    "each of the ten actions was selected according to a normal distribution with mean zero and unit\n",
    "variance, and then the actual rewards were selected according to a mean q⇤(a), unit-variance\n",
    "normal distribution, as suggested by these gray distributions.'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate the data\n",
    "arms = 10\n",
    "arms_q_values = np.random.normal(0, 1, arms)\n",
    "timesteps = 10000\n",
    "arms_values_over_time = np.zeros(timesteps)\n",
    "\n",
    "arm = np.min(arms_q_values)\n",
    "for i in range(timesteps):\n",
    "    arms_values_over_time[i] = np.random.normal(arm, 1)\n",
    "\n",
    "# Create a violin plot based on the data in arms_values_over_time\n",
    "plt.violinplot(arms_values_over_time)\n",
    "plt.title('Violin Plot of Arms Values Over Time')\n",
    "plt.xlabel('Arms')\n",
    "plt.ylabel('Values')\n",
    "\n",
    "# Calculate the mean of the distribution\n",
    "mean_value = np.mean(arms_values_over_time)\n",
    "\n",
    "# Add a shorter marker/error line for the mean of the distribution\n",
    "plt.axhline(mean_value, color='r', linestyle='--', linewidth=1, xmin=0.45, xmax=0.55)\n",
    "\n",
    "# Get the current axis\n",
    "ax = plt.gca()\n",
    "\n",
    "# Get the right end of the error line\n",
    "xmax = ax.get_xlim()[1] * 0.55\n",
    "print (xmax, ax.get_xlim()[1])\n",
    "\n",
    "# Add text relative to the right end of the error line\n",
    "plt.text(1.45 * xmax + 0.02 * ax.get_xlim()[1], mean_value, f'q({np.argmin(arms_q_values)})', color='r', verticalalignment='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
